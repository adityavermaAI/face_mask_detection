{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, face_recognition, datetime, mysql.connector\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "# import pickle\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Conv2D,MaxPooling2D\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abhishek Patel', 'Abhishek Sharma', 'Abhishek Singh', 'Aditya Verma', 'Anoop Kumar', 'Kamendra Kumar', 'Parimal Shrivastav', 'Prince Kumar', 'Rohit Maurya', 'Sagar Maurya', 'Shiv Kumar', 'Shivam Singh', 'Shubham Rajput', 'Umar Singh']\n",
      "ENCODING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "path = 'faces'\n",
    "people_met = []\n",
    "people_names = []\n",
    "people_names_with_ex = os.listdir(path)\n",
    "# print(people_names_with_ex)\n",
    "\n",
    "for person in people_names_with_ex:\n",
    "    # print(person)\n",
    "    person_m = cv2.imread(f'{path}/{person}')\n",
    "    people_met.append(person_m)\n",
    "    people_names.append(os.path.splitext(person)[0])\n",
    "\n",
    "print(people_names)\n",
    "\n",
    "def getEncodings(met_list):\n",
    "    encodings = []\n",
    "    for met in met_list:\n",
    "        met_rgb = cv2.cvtColor(met, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(met_rgb)[0]\n",
    "        encodings.append(encode)\n",
    "        # print(encodings)\n",
    "    return(encodings)\n",
    "\n",
    "people_encodings = getEncodings(people_met)\n",
    "print('ENCODING COMPLETE')\n",
    "# print(len(getEncodings(people_met)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceRecog(img):\n",
    "    cam_image = img\n",
    "    cam_image_small = cv2.resize(cam_image, (0,0), None, 0.25, 0.25)\n",
    "    cam_image_small = cv2.cvtColor(cam_image_small, cv2.COLOR_BGR2RGB)\n",
    "    faces_loc_cur_frame = face_recognition.face_locations(cam_image_small)\n",
    "    encodings_cur_frame = face_recognition.face_encodings(cam_image_small, faces_loc_cur_frame)\n",
    "    \n",
    "    for en_cur_frame in encodings_cur_frame:\n",
    "        matches = face_recognition.compare_faces(people_encodings, en_cur_frame, 0.5)\n",
    "        face_dis = face_recognition.face_distance(people_encodings, en_cur_frame)\n",
    "#         print(face_dis)\n",
    "#         print(matches)z\n",
    "        match_index = np.argmin(face_dis)\n",
    "        if matches[match_index]:\n",
    "            name = people_names[match_index]\n",
    "            return name\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(host= \"localhost\", user= \"root\", password= \"**************\", database=\"facedb\")\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(img, name):\n",
    "        now = datetime.datetime.now()\n",
    "        date = datetime.date.today()\n",
    "        dtstring = date.strftime('%Y-%m-%d')\n",
    "        tstring = now.strftime('%H:%M:%S')\n",
    "        mycursor.execute(\"insert into DATA(NAME, DATE, TIME) values(%s, %s, %s)\", (name, dtstring, tstring))\n",
    "        mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path='dataset'\n",
    "# categories=os.listdir(data_path)\n",
    "# labels=[i for i in range(len(categories))]\n",
    "\n",
    "# label_dict=dict(zip(categories,labels))\n",
    "                \n",
    "# print(label_dict)\n",
    "# print(categories)\n",
    "# print(labels)\n",
    "\n",
    "# img_size=100\n",
    "# data=[]\n",
    "# target=[]\n",
    "\n",
    "\n",
    "# for category in categories:\n",
    "#     folder_path=os.path.join(data_path,category)\n",
    "#     img_names=os.listdir(folder_path)\n",
    "        \n",
    "#     for img_name in img_names:\n",
    "#         img_path=os.path.join(folder_path,img_name)\n",
    "#         img=cv2.imread(img_path)\n",
    "\n",
    "#         try:\n",
    "#             gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#             resized=cv2.resize(gray,(img_size,img_size))\n",
    "#             data.append(resized)\n",
    "#             target.append(label_dict[category])\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print('Exception:',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=np.array(data)/255.0\n",
    "# print('data.shape = ',data.shape)\n",
    "# data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
    "# target=np.array(target)\n",
    "# print('\\ntargets = ',target)\n",
    "# print('target.shape = ',target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = {}\n",
    "# db[\"data\"] = data\n",
    "# db[\"target\"] = target\n",
    "\n",
    "# with open('database', 'ab') as file:\n",
    "#     pickle.dump(db, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('database', 'rb') as file:\n",
    "#     db = pickle.load(file)\n",
    "    \n",
    "# data = db[\"data\"]\n",
    "# target = db[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('data.shape = ',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_data, test_data, train_target, test_target = train_test_split(data, target,test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data, test_data, train_target, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "\n",
    "# model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(Conv2D(100,(3,3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(50,activation='relu'))\n",
    "\n",
    "# model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 6\n",
    "# num_batch_size = 16\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath='weights.best.basic_cnn.hdf5', \n",
    "#                                verbose=1, save_best_only=True)\n",
    "# start = datetime.datetime.now()\n",
    "\n",
    "# history = model.fit(train_data, train_target, batch_size=num_batch_size, epochs=num_epochs, validation_data=(test_data, test_target), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "# duration = datetime.datetime.now() - start\n",
    "# print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'],'r',label='training loss')\n",
    "# plt.plot(history.history['val_loss'],label='validation loss')\n",
    "# plt.xlabel('# epochs')\n",
    "# plt.ylabel('loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(history.history['accuracy'],'r',label='training accuracy')\n",
    "# plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "# plt.xlabel('# epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# print(model.evaluate(test_data,test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# pred_target = model.predict_classes(test_data)\n",
    "# print(test_target)\n",
    "# disp = confusion_matrix(test_target, pred_target)\n",
    "# print(disp)\n",
    "\n",
    "# disp2 = classification_report(test_target, pred_target)\n",
    "# print(disp2)\n",
    "\n",
    "\n",
    "# sns.heatmap(disp, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weights.best.basic_cnn.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011334121\n",
      "99\n",
      "Abhishek Patel\n",
      "NO MASK\n"
     ]
    }
   ],
   "source": [
    "face_clsfr = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "source = cv2.VideoCapture(0)\n",
    "\n",
    "labels_dict = {0:'NO MASK',1:'MASK'}\n",
    "color_dict = {0:(0,0,255),1:(0,255,0)}\n",
    "\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret,img = source.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_clsfr.detectMultiScale(gray,1.3,5)\n",
    "            \n",
    "    for (x,y,w,h) in faces:\n",
    "        face_img = gray[y:y+w,x:x+w]\n",
    "        face_crop = img[y:y+w,x:x+w]\n",
    "        resized = cv2.resize(face_img,(100,100))\n",
    "        normalized = resized/255.0\n",
    "        reshaped = np.reshape(normalized,(1,100,100,1))\n",
    "        result = model.predict(reshaped)[0][0]\n",
    "        print(result)\n",
    "\n",
    "        if result<0.5:\n",
    "            label = 0\n",
    "            percentage  =  int((1-result)*100)\n",
    "            print(percentage)\n",
    "            name = faceRecog(face_crop)\n",
    "            save_data(img, name)\n",
    "            print(name)\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h), color_dict[label], 2)\n",
    "            cv2.rectangle(img,(x,y-40),(x+w,y), color_dict[label], -1)\n",
    "            cv2.putText(img, labels_dict[label], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "            print(labels_dict[label])\n",
    "            cv2.putText(img, str(percentage)+'%', (x+150, y-10), cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "            cv2.putText(img, name, (x,y+h+20), cv2.FONT_HERSHEY_COMPLEX, 0.75, (255,255,255), 2)\n",
    "        else:\n",
    "            label = 1\n",
    "            percentage  =  int((result)*100)\n",
    "            print(percentage)\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h), color_dict[label], 2)\n",
    "            cv2.rectangle(img,(x,y-40),(x+w,y), color_dict[label], -1)\n",
    "            cv2.putText(img, labels_dict[label], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "            print(labels_dict[label])\n",
    "            cv2.putText(img, str(percentage)+'%', (x+150, y-10), cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "    cv2.imshow('LIVE_CAM',img)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if(key == 27):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
